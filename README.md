# Frost - AI-Powered File Browser

A modern Next.js application with intelligent file analysis capabilities.

## ğŸš€ Quick Start

### Prerequisites
1. **Install Ollama**: Download from [ollama.ai](https://ollama.ai)
2. **Start Ollama**: `ollama serve`
3. **Install AI Model**: `ollama pull gemma2:27b`

### One-Command Setup
```bash
npm run ai
```
This starts the Next.js app and connects to your local AI model.

### Alternative Commands
```bash
# Using npm script
npm run ai-start

# Using direct script
./start-all.sh

# Manual setup (if needed)
npm install
./start-all.sh
```

## âœ¨ Features

- **ğŸ“ File Browser**: 3-column layout with file list, editor, and AI insights
- **âœï¸ File Editor**: Create, edit, rename, and save files
- **ğŸ¤– AI Analysis**: Intelligent content analysis with insights and suggestions
- **ğŸ”’ Local Processing**: Everything runs on your machine (no external APIs)
- **ğŸ¨ Modern UI**: Clean, responsive design with blue theme

## ğŸ¯ How to Use

1. **Start the app**: `npm run ai`
2. **Open browser**: Go to http://localhost:3000
3. **Select a file**: Click any file in the left column
4. **View AI insights**: See analysis in the right column
5. **Edit files**: Use the middle column to create/edit files

## ğŸ¤– AI Analysis Features

The AI analysis provides:
- **ğŸ“‹ Summary**: Brief overview of file content
- **ğŸ”‘ Key Points**: Important observations about structure and purpose
- **ğŸ’¡ Insights**: Notable patterns, themes, and characteristics
- **ğŸ’­ Suggestions**: Recommendations for improvement

## ğŸ› ï¸ Tech Stack

- **Frontend**: Next.js 14, TypeScript, Tailwind CSS
- **AI Model**: Gemma2:27b (27.2B parameters) via Ollama
- **File System**: Local file operations with API endpoints
- **Processing**: All AI analysis happens locally on your machine

## ğŸ”§ Development

### Manual Server Management
```bash
# Terminal 1: Start Ollama AI server
ollama serve

# Terminal 2: Start Next.js
npm run dev
```

### Testing AI Analysis
```bash
# Test through Next.js API (recommended)
curl -X POST http://localhost:3000/api/analyze \
  -H "Content-Type: application/json" \
  -d '{"content":"your content here","filename":"test.txt"}'

# Test Ollama directly
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model":"gemma2:27b","prompt":"Analyze this content: your content here"}'
```

## ğŸ“ Project Structure

```
frost/
â”œâ”€â”€ app/                    # Next.js app directory
â”‚   â”œâ”€â”€ api/               # API routes
â”‚   â””â”€â”€ page.tsx           # Main page
â”œâ”€â”€ components/            # React components
â”‚   â”œâ”€â”€ FileBrowser.tsx    # Main file browser
â”‚   â”œâ”€â”€ FileEditor.tsx     # File editing component
â”‚   â””â”€â”€ InsightsPanel.tsx  # AI insights display
â”œâ”€â”€ data/                  # Sample files
â”œâ”€â”€ start-all.sh           # Unified startup script
â””â”€â”€ package.json           # Node.js dependencies
```

## ğŸ‰ Enjoy!

Your AI-powered file browser is ready to use! The system automatically handles all the complexity of running both the web app and AI analysis server together.